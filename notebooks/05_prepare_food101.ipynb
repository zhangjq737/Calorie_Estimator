{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81654890-227c-4c70-80b5-5216f29d27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d67089-7f50-4c6d-9727-6a30cfdc82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Downloading Food-101 dataset\n",
      "Size: ~5GB (4.65GB exact)\n",
      "Estimated time: 10-20 minutes (depends on internet speed)\n",
      "============================================================\n",
      "\n",
      "✓ Already downloaded: /Users/jasonzhang/calorie_estimator/datasets/food-101.tar.gz\n",
      "  Size: 4.65 GB\n",
      "\n",
      "✓ Already extracted: /Users/jasonzhang/calorie_estimator/datasets/food-101\n",
      "\n",
      "============================================================\n",
      "Dataset Ready!\n",
      "============================================================\n",
      "Location: /Users/jasonzhang/calorie_estimator/datasets/food-101\n",
      "Total size: ~7 GB (compressed + extracted)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Download Food-101 with progress bar\n",
    "class DownloadProgressBar(tqdm):\n",
    "    \"\"\"Progress bar for urllib downloads\"\"\"\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "def download_with_progress(url, output_path):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True, \n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, \n",
    "                                   reporthook=t.update_to)\n",
    "\n",
    "# Create directory\n",
    "dataset_dir = Path.home() / \"calorie_estimator\" / \"datasets\"\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Downloading Food-101 dataset\")\n",
    "print(\"Size: ~5GB (4.65GB exact)\")\n",
    "print(\"Estimated time: 10-20 minutes (depends on internet speed)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Download\n",
    "url = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
    "tar_path = dataset_dir / \"food-101.tar.gz\"\n",
    "\n",
    "if not tar_path.exists():\n",
    "    print(f\"\\nDownloading to: {tar_path}\")\n",
    "    download_with_progress(url, tar_path)\n",
    "    print(\"\\n✓ Download complete!\")\n",
    "else:\n",
    "    print(f\"\\n✓ Already downloaded: {tar_path}\")\n",
    "    print(f\"  Size: {tar_path.stat().st_size / (1024**3):.2f} GB\")\n",
    "\n",
    "# Extract with progress\n",
    "food101_dir = dataset_dir / \"food-101\"\n",
    "if not food101_dir.exists():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Extracting dataset...\")\n",
    "    print(\"This will take 5-10 minutes\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with tarfile.open(tar_path) as tar:\n",
    "        members = tar.getmembers()\n",
    "        for member in tqdm(members, desc=\"Extracting\"):\n",
    "            tar.extract(member, dataset_dir)\n",
    "    \n",
    "    print(\"\\n✓ Extraction complete!\")\n",
    "else:\n",
    "    print(f\"\\n✓ Already extracted: {food101_dir}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Dataset Ready!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Location: {food101_dir}\")\n",
    "print(f\"Total size: ~7 GB (compressed + extracted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa728707-3ccc-4b95-8caf-65d5f15f5819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "  Images: /Users/jasonzhang/calorie_estimator/datasets/food-101/images\n",
      "  Metadata: /Users/jasonzhang/calorie_estimator/datasets/food-101/meta\n",
      "\n",
      "Total classes: 101\n",
      "First 10 classes: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito']\n",
      "\n",
      "Images in 'apple_pie': 1000\n",
      "\n",
      "Training images: 75750\n",
      "Test images: 25250\n",
      "Total: 101000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Explore dataset\n",
    "food101_path = Path.home() / \"calorie_estimator\" / \"datasets\" / \"food-101\"\n",
    "\n",
    "# Check structure\n",
    "print(\"Dataset structure:\")\n",
    "print(f\"  Images: {food101_path / 'images'}\")\n",
    "print(f\"  Metadata: {food101_path / 'meta'}\")\n",
    "\n",
    "# Count classes\n",
    "classes_dir = food101_path / \"images\"\n",
    "classes = sorted([d.name for d in classes_dir.iterdir() if d.is_dir()])\n",
    "print(f\"\\nTotal classes: {len(classes)}\")\n",
    "print(f\"First 10 classes: {classes[:10]}\")\n",
    "\n",
    "# Check image count\n",
    "sample_class = classes[0]\n",
    "sample_images = list((classes_dir / sample_class).glob(\"*.jpg\"))\n",
    "print(f\"\\nImages in '{sample_class}': {len(sample_images)}\")\n",
    "\n",
    "# Read train/test split\n",
    "train_file = food101_path / \"meta\" / \"train.txt\"\n",
    "test_file = food101_path / \"meta\" / \"test.txt\"\n",
    "\n",
    "with open(train_file) as f:\n",
    "    train_list = f.readlines()\n",
    "with open(test_file) as f:\n",
    "    test_list = f.readlines()\n",
    "\n",
    "print(f\"\\nTraining images: {len(train_list)}\")\n",
    "print(f\"Test images: {len(test_list)}\")\n",
    "print(f\"Total: {len(train_list) + len(test_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45677617-dcb7-4d59-839c-7e0a8c35640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Convert Food-101 to YOLO format\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "def convert_food101_to_yolo(food101_path, output_path, subset_classes=None):\n",
    "    \"\"\"\n",
    "    Convert Food-101 dataset to YOLO format\n",
    "    \n",
    "    Args:\n",
    "        food101_path: Path to food-101 directory\n",
    "        output_path: Where to save YOLO format dataset\n",
    "        subset_classes: List of classes to use (None = use all 101)\n",
    "    \"\"\"\n",
    "    \n",
    "    food101_path = Path(food101_path)\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    # Create YOLO directory structure\n",
    "    (output_path / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all classes\n",
    "    all_classes = sorted([d.name for d in (food101_path / \"images\").iterdir() if d.is_dir()])\n",
    "    \n",
    "    # Use subset if specified\n",
    "    if subset_classes:\n",
    "        classes = [c for c in all_classes if c in subset_classes]\n",
    "        print(f\"Using {len(classes)} classes: {classes}\")\n",
    "    else:\n",
    "        classes = all_classes\n",
    "        print(f\"Using all {len(classes)} classes\")\n",
    "    \n",
    "    # Create class_to_idx mapping\n",
    "    class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "    \n",
    "    # Read train/test splits\n",
    "    with open(food101_path / \"meta\" / \"train.txt\") as f:\n",
    "        train_files = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    with open(food101_path / \"meta\" / \"test.txt\") as f:\n",
    "        test_files = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    # Filter for selected classes\n",
    "    if subset_classes:\n",
    "        train_files = [f for f in train_files if f.split('/')[0] in classes]\n",
    "        test_files = [f for f in test_files if f.split('/')[0] in classes]\n",
    "    \n",
    "    print(f\"\\nProcessing {len(train_files)} training images...\")\n",
    "    print(f\"Processing {len(test_files)} validation images...\")\n",
    "    \n",
    "    # Process training set\n",
    "    for file_path in tqdm(train_files, desc=\"Converting train\"):\n",
    "        class_name, img_name = file_path.split('/')\n",
    "        class_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # Copy image\n",
    "        src_img = food101_path / \"images\" / class_name / f\"{img_name}.jpg\"\n",
    "        dst_img = output_path / \"images\" / \"train\" / f\"{class_name}_{img_name}.jpg\"\n",
    "        shutil.copy(src_img, dst_img)\n",
    "        \n",
    "        # Create label (full image bounding box for classification)\n",
    "        # Format: class_id x_center y_center width height (normalized)\n",
    "        label_file = output_path / \"labels\" / \"train\" / f\"{class_name}_{img_name}.txt\"\n",
    "        with open(label_file, 'w') as f:\n",
    "            f.write(f\"{class_idx} 0.5 0.5 1.0 1.0\\n\")\n",
    "    \n",
    "    # Process test/validation set\n",
    "    for file_path in tqdm(test_files, desc=\"Converting val\"):\n",
    "        class_name, img_name = file_path.split('/')\n",
    "        class_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # Copy image\n",
    "        src_img = food101_path / \"images\" / class_name / f\"{img_name}.jpg\"\n",
    "        dst_img = output_path / \"images\" / \"val\" / f\"{class_name}_{img_name}.jpg\"\n",
    "        shutil.copy(src_img, dst_img)\n",
    "        \n",
    "        # Create label\n",
    "        label_file = output_path / \"labels\" / \"val\" / f\"{class_name}_{img_name}.txt\"\n",
    "        with open(label_file, 'w') as f:\n",
    "            f.write(f\"{class_idx} 0.5 0.5 1.0 1.0\\n\")\n",
    "    \n",
    "    # Create data.yaml\n",
    "    data_yaml = {\n",
    "        'path': str(output_path.absolute()),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': {idx: name for name, idx in class_to_idx.items()}\n",
    "    }\n",
    "    \n",
    "    with open(output_path / \"data.yaml\", 'w') as f:\n",
    "        yaml.dump(data_yaml, f, sort_keys=False)\n",
    "    \n",
    "    print(f\"\\n✓ Conversion complete!\")\n",
    "    print(f\"✓ Dataset saved to: {output_path}\")\n",
    "    print(f\"✓ Classes: {len(classes)}\")\n",
    "    print(f\"✓ Training images: {len(train_files)}\")\n",
    "    print(f\"✓ Validation images: {len(test_files)}\")\n",
    "    \n",
    "    return output_path / \"data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69cc866-77d2-47c2-91ba-60d884a5a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 101 classes\n",
      "\n",
      "Processing 75750 training images...\n",
      "Processing 25250 validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train: 100%|█████████████████████████████████████████| 75750/75750 [00:33<00:00, 2250.10it/s]\n",
      "Converting val: 100%|███████████████████████████████████████████| 25250/25250 [00:10<00:00, 2319.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Conversion complete!\n",
      "✓ Dataset saved to: /Users/jasonzhang/calorie_estimator/datasets/food101_yolo\n",
      "✓ Classes: 101\n",
      "✓ Training images: 75750\n",
      "✓ Validation images: 25250\n",
      "\n",
      "data.yaml location: /Users/jasonzhang/calorie_estimator/datasets/food101_yolo/data.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Run conversion\n",
    "food101_path = Path.home() / \"calorie_estimator\" / \"datasets\" / \"food-101\"\n",
    "yolo_output = Path.home() / \"calorie_estimator\" / \"datasets\" / \"food101_yolo\"\n",
    "\n",
    "# Option A: Use ALL 101 classes (recommended for full project)\n",
    "data_yaml_path = convert_food101_to_yolo(food101_path, yolo_output)\n",
    "\n",
    "# Option B: Quick test with subset (10-20 classes) - faster training\n",
    "# subset = ['pizza', 'apple_pie', 'hamburger', 'hot_dog', 'ice_cream', \n",
    "#           'french_fries', 'sushi', 'steak', 'chicken_wings', 'donuts']\n",
    "# data_yaml_path = convert_food101_to_yolo(food101_path, yolo_output, subset)\n",
    "\n",
    "print(f\"\\ndata.yaml location: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bbc05-db69-48d4-bddb-6542335721e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
